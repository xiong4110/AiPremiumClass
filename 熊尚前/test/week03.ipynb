{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载处理\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "train_data = FashionMNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_data = FashionMNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "train_data[1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.数据预处理\n",
    "2.构建模型\n",
    "3.定制模型损失函数和优化器\n",
    "4.训练并观察超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 64])\n",
      "tensor([[ 0.1406, -0.0086,  0.0047,  0.5930, -0.1242, -0.1971, -0.1275, -0.1839,\n",
      "          0.4931,  0.5259],\n",
      "        [ 0.2453, -0.0844,  0.1671,  0.5047, -0.1551, -0.1343, -0.0358, -0.3185,\n",
      "          0.3625,  0.2968],\n",
      "        [ 0.2368, -0.0185,  0.0830,  0.6275, -0.0526, -0.1607, -0.1085, -0.3026,\n",
      "          0.4020,  0.4678],\n",
      "        [ 0.2135,  0.0905, -0.1385,  0.6620, -0.2132, -0.0904, -0.2322, -0.2047,\n",
      "          0.6250,  0.5907],\n",
      "        [ 0.0706, -0.0469, -0.0186,  0.5980, -0.1463, -0.2838, -0.1256, -0.3653,\n",
      "          0.3999,  0.5538]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0984, 0.0847, 0.0858, 0.1546, 0.0755, 0.0702, 0.0752, 0.0711, 0.1399,\n",
      "         0.1446],\n",
      "        [0.1137, 0.0818, 0.1051, 0.1474, 0.0762, 0.0778, 0.0858, 0.0647, 0.1278,\n",
      "         0.1197],\n",
      "        [0.1080, 0.0837, 0.0926, 0.1596, 0.0808, 0.0726, 0.0764, 0.0630, 0.1274,\n",
      "         0.1360],\n",
      "        [0.1019, 0.0901, 0.0717, 0.1596, 0.0665, 0.0752, 0.0653, 0.0671, 0.1538,\n",
      "         0.1486],\n",
      "        [0.0954, 0.0848, 0.0872, 0.1616, 0.0768, 0.0669, 0.0784, 0.0617, 0.1326,\n",
      "         0.1546]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# x输入(60000,784)\n",
    "# 隐藏层(784,64) 参数矩阵\n",
    "# 隐藏层(64) 偏置\n",
    "# 输出层参数矩阵(64,10)\n",
    "# 输出层偏置(10,)\n",
    "# y结果(60000,10)\n",
    "linear = nn.Linear(in_features=784, out_features=64, bias=True)\n",
    "out = linear(torch.randn(5,784))\n",
    "act = nn.Sigmoid()\n",
    "out1 = act(out)\n",
    "\n",
    "linear2 = nn.Linear(in_features=64, out_features=10, bias=True)\n",
    "print(out1.shape)\n",
    "out3 = linear2(out1)\n",
    "print(out3)\n",
    "final = nn.Softmax(dim=1)\n",
    "out4 = final(out3)\n",
    "print(out4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (1): Sigmoid()\n",
       "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所有的结构串联\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28*28, 256),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0167, -0.0294, -0.0254,  ..., -0.0247, -0.0297, -0.0018],\n",
       "         [ 0.0109,  0.0079, -0.0167,  ...,  0.0229, -0.0060,  0.0067],\n",
       "         [ 0.0196,  0.0124, -0.0349,  ...,  0.0352,  0.0124,  0.0115],\n",
       "         ...,\n",
       "         [-0.0197,  0.0273,  0.0195,  ...,  0.0059, -0.0136,  0.0346],\n",
       "         [ 0.0280, -0.0330, -0.0143,  ..., -0.0223,  0.0242,  0.0010],\n",
       "         [ 0.0031, -0.0142,  0.0346,  ..., -0.0157,  0.0017,  0.0153]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0318,  0.0021,  0.0082, -0.0189,  0.0306,  0.0338, -0.0257,  0.0001,\n",
       "          0.0244,  0.0089,  0.0050,  0.0245,  0.0062, -0.0044, -0.0331, -0.0313,\n",
       "         -0.0170,  0.0333,  0.0346, -0.0055,  0.0210,  0.0031,  0.0064,  0.0241,\n",
       "          0.0201,  0.0242,  0.0030, -0.0259,  0.0210,  0.0092,  0.0176, -0.0227,\n",
       "         -0.0185, -0.0035, -0.0301,  0.0270, -0.0313, -0.0192,  0.0052,  0.0094,\n",
       "         -0.0258,  0.0008,  0.0171, -0.0176, -0.0252, -0.0185,  0.0301, -0.0304,\n",
       "         -0.0207,  0.0236,  0.0342,  0.0221,  0.0249, -0.0189,  0.0041,  0.0042,\n",
       "          0.0076, -0.0071, -0.0239,  0.0036,  0.0241,  0.0110, -0.0111,  0.0112,\n",
       "         -0.0271,  0.0106,  0.0041, -0.0219, -0.0161, -0.0292,  0.0074,  0.0343,\n",
       "         -0.0055,  0.0285, -0.0146,  0.0158,  0.0217, -0.0138,  0.0340, -0.0063,\n",
       "          0.0278,  0.0287,  0.0283,  0.0040, -0.0221, -0.0287,  0.0319,  0.0349,\n",
       "         -0.0266,  0.0226, -0.0047,  0.0075,  0.0294,  0.0055,  0.0077,  0.0170,\n",
       "         -0.0013,  0.0140, -0.0339, -0.0261,  0.0267, -0.0330,  0.0145, -0.0250,\n",
       "         -0.0174,  0.0307,  0.0343,  0.0050, -0.0337,  0.0331, -0.0263, -0.0022,\n",
       "          0.0031,  0.0214, -0.0299,  0.0248, -0.0066,  0.0133,  0.0196, -0.0001,\n",
       "          0.0096,  0.0293,  0.0317, -0.0013, -0.0254, -0.0348,  0.0171,  0.0039,\n",
       "          0.0226, -0.0140, -0.0192, -0.0141,  0.0132,  0.0130,  0.0035,  0.0003,\n",
       "          0.0023,  0.0253, -0.0337, -0.0137, -0.0101, -0.0150,  0.0110, -0.0166,\n",
       "          0.0121,  0.0271, -0.0303, -0.0216,  0.0209,  0.0336,  0.0126, -0.0166,\n",
       "          0.0052, -0.0199,  0.0346, -0.0249, -0.0020,  0.0060, -0.0137, -0.0028,\n",
       "          0.0222,  0.0140, -0.0168, -0.0232,  0.0230, -0.0086,  0.0290, -0.0139,\n",
       "          0.0107,  0.0075, -0.0021, -0.0005, -0.0195, -0.0184, -0.0137, -0.0062,\n",
       "          0.0206,  0.0007,  0.0103,  0.0245, -0.0106, -0.0153,  0.0142, -0.0300,\n",
       "          0.0040, -0.0146, -0.0013, -0.0141, -0.0257,  0.0355,  0.0301, -0.0356,\n",
       "          0.0253, -0.0185, -0.0176, -0.0258, -0.0312,  0.0355, -0.0144,  0.0303,\n",
       "         -0.0076, -0.0175,  0.0221, -0.0015, -0.0139, -0.0108,  0.0283,  0.0140,\n",
       "         -0.0070,  0.0203, -0.0063,  0.0094,  0.0115, -0.0001, -0.0119,  0.0332,\n",
       "         -0.0206, -0.0062, -0.0203, -0.0148,  0.0212,  0.0042,  0.0353, -0.0336,\n",
       "          0.0255,  0.0142, -0.0120, -0.0160,  0.0329, -0.0065, -0.0237, -0.0278,\n",
       "         -0.0354,  0.0245,  0.0012,  0.0102,  0.0120, -0.0022, -0.0290,  0.0064,\n",
       "          0.0324,  0.0171, -0.0158, -0.0300,  0.0225,  0.0188, -0.0265, -0.0039,\n",
       "          0.0229,  0.0189, -0.0017, -0.0169,  0.0027, -0.0071,  0.0308,  0.0014],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0382, -0.0251,  0.0471,  ...,  0.0432, -0.0253, -0.0345],\n",
       "         [ 0.0056,  0.0570,  0.0488,  ...,  0.0029, -0.0285, -0.0430],\n",
       "         [ 0.0138,  0.0174,  0.0335,  ...,  0.0518,  0.0104,  0.0499],\n",
       "         ...,\n",
       "         [ 0.0519,  0.0532, -0.0112,  ..., -0.0572, -0.0300,  0.0379],\n",
       "         [ 0.0251,  0.0083,  0.0446,  ..., -0.0439, -0.0125,  0.0233],\n",
       "         [ 0.0226, -0.0402,  0.0425,  ..., -0.0542, -0.0350,  0.0295]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0137,  0.0455, -0.0577,  0.0273,  0.0394, -0.0291,  0.0353, -0.0297,\n",
       "          0.0141,  0.0517], requires_grad=True)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss() # 交叉熵损失函数，多分类问题一般都是用交叉熵损失函数\n",
    "print(loss_fn)\n",
    "# 优化器 模型参数更新\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # 随机梯度下降优化器，学习率为0.01\n",
    "[param for param in model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch fashionmnist数据集 神经网络搭建和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms.v2 import ToTensor # 转换图像数据为张量\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader # 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "LR = 0.01\n",
    "epochs = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xiong\\.conda\\envs\\py312\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 数据集加载\n",
    "train_data = FashionMNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_data = FashionMNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "# print(train_data[0])\n",
    "# print(type(train_data[0][0]))\n",
    "# print(type(train_data[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)  # 随机梯度下降优化器\n",
    "# count = 0\n",
    "# for param in model.parameters():\n",
    "#     print(param)\n",
    "#     count += 1\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "tensor([7, 5, 4, 9, 0, 7, 5, 8, 5, 4, 2, 4, 8, 6, 7, 9, 4, 1, 0, 8, 5, 0, 1, 4,\n",
      "        7, 6, 9, 6, 9, 1, 7, 1, 1, 6, 4, 9, 5, 4, 9, 1, 0, 2, 2, 4, 6, 6, 3, 4,\n",
      "        2, 1, 6, 2, 4, 8, 8, 4, 4, 0, 2, 6, 1, 6, 3, 7, 4, 6, 1, 4, 7, 2, 4, 5,\n",
      "        5, 5, 0, 7, 6, 4, 2, 2, 7, 8, 6, 3, 5, 5, 4, 2, 8, 2, 6, 0, 5, 4, 4, 6,\n",
      "        0, 8, 6, 8, 1, 7, 7, 9, 8, 7, 0, 0, 1, 5, 9, 6, 0, 2, 8, 2, 3, 7, 8, 4,\n",
      "        3, 0, 8, 3, 6, 7, 9, 7])\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dl))\n",
    "for a in train_dl:\n",
    "    print(a[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss: 2.298168897628784\n",
      "Epoch:1 Loss: 2.2941811084747314\n",
      "Epoch:2 Loss: 2.2828450202941895\n",
      "Epoch:3 Loss: 2.272071361541748\n",
      "Epoch:4 Loss: 2.2442948818206787\n",
      "Epoch:5 Loss: 2.1958401203155518\n",
      "Epoch:6 Loss: 2.12853741645813\n",
      "Epoch:7 Loss: 1.9328991174697876\n",
      "Epoch:8 Loss: 1.7977286577224731\n",
      "Epoch:9 Loss: 1.6834653615951538\n",
      "Epoch:10 Loss: 1.6045740842819214\n",
      "Epoch:11 Loss: 1.4776787757873535\n",
      "Epoch:12 Loss: 1.390397071838379\n",
      "Epoch:13 Loss: 1.2965580224990845\n",
      "Epoch:14 Loss: 1.1460697650909424\n",
      "Epoch:15 Loss: 1.216450810432434\n",
      "Epoch:16 Loss: 1.1548116207122803\n",
      "Epoch:17 Loss: 1.0856159925460815\n",
      "Epoch:18 Loss: 1.1114213466644287\n",
      "Epoch:19 Loss: 1.0018080472946167\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):    \n",
    "    for data, target in train_dl:\n",
    "        # 前向运算\n",
    "        output = model(data.reshape(-1, 784))\n",
    "        # 计算损失\n",
    "        loss = loss_fn(output, target)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad() # 所有参数梯度清零\n",
    "        loss.backward()\n",
    "        optimizer.step() # 更新参数 \n",
    "    print(f'Epoch:{epoch} Loss: {loss.item()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61 %\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "test_dl = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "current = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dl:\n",
    "        output = model(data.reshape(-1, 28*28))\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += target.size(0)\n",
    "        current += (predicted == target).sum().item()\n",
    "print('Accuracy: %d %%' % (100 * current / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
